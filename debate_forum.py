#!/usr/bin/env python3
"""
Attractor-Aware Debate Forum v4

Uses the modular attractor_steering.py system for detection.
Requires a filter_config.json generated by the Lagrange Mapper pipeline.

Usage:
    python debate_forum.py                    # Uses default model config
    python debate_forum.py --model granite-3.1-8b
    python debate_forum.py --compare          # Show filtered vs unfiltered side-by-side
    python debate_forum.py --model local-model --compare
"""

import json
import random
import os
import re
import requests
from typing import List, Dict, Set, Optional
from dataclasses import dataclass, field
from collections import Counter
from pathlib import Path

# Import the steering system
from attractor_steering import (
    AttractorSteering, 
    SteeringConfig, 
    DetectionResult,
    load_steering,
    load_dual_steering,
    DualModeAttractorSteering,
    FORCED_ALTERNATIVES,
    # Two-phase filtering
    identify_attractor_segments,
    build_rephrase_prompt,
    two_phase_filter
)

# ============================================================================
# CONFIGURATION
# ============================================================================

# LLM Backend
BACKEND = "local"  # "local" or "anthropic"
LOCAL_URL = "http://localhost:1234/v1/chat/completions"
LOCAL_MODEL = "local-model"

ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY")
ANTHROPIC_MODEL = "claude-3-5-haiku-20241022"

# Steering
DEFAULT_MODEL_NAME = "local-model"  # Must match a folder in filter_configs/
DEFAULT_CONFIG_DIR = "filter_configs"
USE_EMBEDDINGS = True
MIN_RETRY_SCORE = 2.0   # Only retry if score is at least this high (saves API calls)
CLEAN_BASELINE_THRESHOLD = 2.5  # Skip ALL filtering if baseline score is below this (adaptive threshold)
USE_TWO_PHASE_FILTERING = True  # Use targeted rephrasing instead of full regeneration
MAX_REPHRASE_ATTEMPTS = 2  # Max attempts for Phase 2 targeted rephrasing
COMPARE_MODE = False  # Show both filtered and unfiltered responses
USE_DUAL_MODE = True  # Use both neutral and controversial attractors if available
CONTROVERSIAL_WEIGHT = 2.0  # How much to weight controversial attractor matches

# ============================================================================
# TOPIC ANALYSIS
# ============================================================================

@dataclass
class TopicContext:
    """Analyzed topic with exemptions"""
    topic: str
    exempted_keywords: Set[str] = field(default_factory=set)
    
    def summary(self) -> str:
        lines = [f"Topic: {self.topic}"]
        if self.exempted_keywords:
            exempted_list = sorted(self.exempted_keywords)
            if len(exempted_list) > 10:
                lines.append(f"  Exempted: {', '.join(exempted_list[:10])} (+{len(exempted_list)-10} more)")
            else:
                lines.append(f"  Exempted: {', '.join(exempted_list)}")
        return "\n".join(lines)


def analyze_topic(topic: str, steering: 'AttractorSteering' = None) -> TopicContext:
    """
    Analyze topic and determine exemptions.
    
    Simple logic: any attractor keyword that appears in the topic
    is exempted from detection (since it's topic-relevant).
    """
    ctx = TopicContext(topic=topic)
    
    if steering and steering.config.all_keywords:
        # Exempt any attractor keyword found in the topic
        ctx.exempted_keywords = steering.analyze_topic(topic)
    
    return ctx


# ============================================================================
# CHARACTERS
# ============================================================================

CHARACTERS = {
    "traditionalist": {
        "name": "The Traditionalist",
        "intensity": 0.3,
        "system_prompt": """You are The Traditionalist - you believe proven methods and established institutions are undervalued.

Your approach:
- Ask "How did we solve this before technology existed?"
- Reference historical examples, traditional practices, existing institutions
- Be skeptical of solutions requiring new infrastructure or coordination
- Prefer incremental improvements to existing systems

You MUST NOT propose solutions involving: blockchain, DAOs, AI systems, platforms, apps, or digital infrastructure.
Instead, consider: legal reforms, traditional governance, community customs, institutional improvements.""",
    },
    
    "minimalist": {
        "name": "The Minimalist",
        "intensity": 0.8,
        "system_prompt": """You are The Minimalist - you believe the simplest solution is usually best.

Your approach:
- Ask "What's the simplest thing that could possibly work?"
- Strip away complexity, coordination requirements, dependencies
- Prefer individual actions over collective coordination
- Be suspicious of elaborate systems

You MUST NOT propose solutions involving: ecosystems, platforms, networks, multi-stakeholder coordination.
Instead, consider: individual actions, simple rules, direct relationships, minimal intervention.""",
    },
    
    "contrarian": {
        "name": "The Contrarian",
        "intensity": 0.25,
        "system_prompt": """You are The Contrarian - you challenge assumptions and consider opposite approaches.

Your approach:
- Ask "What if the opposite approach is better?"
- Challenge the framing of the problem itself
- Consider whether the problem needs solving at all
- Push back on consensus views

You MUST NOT accept: win-win framings, synergy, or solutions that claim to benefit everyone.
Instead, consider: tradeoffs, who loses, unintended consequences, doing nothing.""",
    },
    
    "philosopher": {
        "name": "The Philosopher",
        "intensity": 0.5,
        "system_prompt": """You are The Philosopher - you question definitions and examine underlying concepts.

Your approach:
- Ask "What do we actually mean by X?"
- Examine assumptions, definitions, values
- Consider the philosophical implications
- Question whether we're solving the right problem

You MUST NOT use: buzzwords, jargon, or technical solutions without examining what they mean.
Instead, consider: conceptual clarity, value tradeoffs, what we're actually optimizing for.""",
    },
    
    "pragmatist": {
        "name": "The Pragmatist",
        "intensity": 0.45,
        "system_prompt": """You are The Pragmatist - you focus on what's actually implementable.

Your approach:
- Ask "Who would actually do this, and why would they?"
- Consider incentives, costs, political feasibility
- Prefer boring solutions that could happen tomorrow
- Be skeptical of solutions requiring behavior change

You MUST NOT propose: utopian visions, solutions requiring mass coordination, or new institutions.
Instead, consider: existing incentives, realistic constraints, incremental changes.""",
    },
}

# ============================================================================
# LLM INTERFACE
# ============================================================================

def call_llm(system_prompt: str, user_prompt: str) -> str:
    """Call the LLM backend"""
    
    if BACKEND == "anthropic":
        return call_anthropic(system_prompt, user_prompt)
    else:
        return call_local(system_prompt, user_prompt)


def call_local(system_prompt: str, user_prompt: str) -> str:
    """Call local LLM via OpenAI-compatible API"""
    try:
        response = requests.post(
            LOCAL_URL,
            headers={"Content-Type": "application/json"},
            json={
                "model": LOCAL_MODEL,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "max_tokens": 500,
                "temperature": 0.8
            },
            timeout=60
        )
        
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content'].strip()
        else:
            return f"[Error: {response.status_code}]"
            
    except Exception as e:
        return f"[Error: {e}]"


def call_anthropic(system_prompt: str, user_prompt: str) -> str:
    """Call Anthropic API"""
    try:
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers={
                "x-api-key": ANTHROPIC_API_KEY,
                "anthropic-version": "2023-06-01",
                "Content-Type": "application/json"
            },
            json={
                "model": ANTHROPIC_MODEL,
                "max_tokens": 500,
                "system": system_prompt,
                "messages": [{"role": "user", "content": user_prompt}]
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()['content'][0]['text'].strip()
        else:
            return f"[Error: {response.status_code}]"
            
    except Exception as e:
        return f"[Error: {e}]"


# ============================================================================
# GENERATION WITH STEERING
# ============================================================================

def build_prompt(
    character: Dict,
    topic: str,
    context: str,
    topic_ctx: Optional[TopicContext],
    is_first_speaker: bool,
    avoidance_prompt: str = ""
) -> tuple:
    """Build system and user prompts for generation"""
    
    system_prompt = character['system_prompt']
    
    # Add topic-specific guidance
    if topic_ctx and topic_ctx.exempted_keywords:
        system_prompt += f"\n\nNote: This topic involves {', '.join(list(topic_ctx.exempted_keywords)[:5])}. You may DISCUSS these concepts freely."
    
    # Build user prompt
    if is_first_speaker:
        user_prompt = f"""Topic: {topic}

You are opening this discussion. State your position clearly and concisely.
Keep your response under 150 words."""
    else:
        user_prompt = f"""Topic: {topic}

DISCUSSION SO FAR:
{context}

Now respond as {character['name']}. You MUST:
1. Directly reference something a previous speaker said
2. Either challenge their claim, build on it, or point out what they missed
3. Add your own distinct perspective

Start by addressing another speaker: "The [Name] claims X, but..."
Keep your response under 150 words."""
    
    if avoidance_prompt:
        user_prompt += avoidance_prompt
    
    return system_prompt, user_prompt


def generate_without_steering(
    char_id: str,
    topic: str,
    context: str,
    topic_ctx: Optional[TopicContext] = None,
    is_first_speaker: bool = False
) -> str:
    """Generate response WITHOUT any attractor steering (for comparison)"""
    
    character = CHARACTERS[char_id]
    system_prompt, user_prompt = build_prompt(
        character, topic, context, topic_ctx, is_first_speaker, ""
    )
    return call_llm(system_prompt, user_prompt)


def generate_with_steering(
    steering: AttractorSteering,
    char_id: str,
    topic: str,
    context: str,
    topic_ctx: Optional[TopicContext] = None,
    is_first_speaker: bool = False,
    verbose: bool = True
) -> tuple:
    """
    Generate response with attractor steering.
    
    Uses two-phase filtering if enabled:
      Phase 1: Identify attractor phrases in unfiltered response
      Phase 2: Request targeted rephrasing of only those segments
    
    Falls back to full regeneration if two-phase filtering doesn't improve score.
    """
    
    character = CHARACTERS[char_id]
    intensity = character.get('intensity', 0.5)  # Per-character intensity
    exempted = topic_ctx.exempted_keywords if topic_ctx else set()
    
    # ========================================
    # INITIAL GENERATION
    # ========================================
    system_prompt, user_prompt = build_prompt(
        character, topic, context, topic_ctx, is_first_speaker, ""
    )
    response = call_llm(system_prompt, user_prompt)
    
    # Check for attractors
    result = steering.detect(response, exempted_keywords=exempted, 
                             intensity=intensity, use_embeddings=USE_EMBEDDINGS)
    
    if verbose:
        status = "⚠️ ATTRACTOR MATCH" if result.is_attracted else "✓"
        print(f"  [Initial] {status} (score: {result.keyword_score:.1f}, intensity: {intensity})")
    
    # ADAPTIVE THRESHOLD: Skip ALL filtering if baseline is already clean
    if result.keyword_score < CLEAN_BASELINE_THRESHOLD:
        if verbose and result.is_attracted:
            print(f"  [Adaptive] Baseline clean ({result.keyword_score:.1f} < {CLEAN_BASELINE_THRESHOLD}), skipping filter")
        return response, result, 1
    
    # Accept immediately if not attracted
    if not result.is_attracted:
        return response, result, 1
    
    # ========================================
    # TWO-PHASE FILTERING (if enabled)
    # ========================================
    if USE_TWO_PHASE_FILTERING and result.flagged_keywords:
        if verbose:
            print(f"  [Two-Phase] Attempting targeted rephrasing...")
        
        rephrased, new_result, improved = two_phase_filter(
            original_response=response,
            result=result,
            steering=steering,
            generate_fn=call_llm,
            exempted_keywords=exempted,
            intensity=intensity,
            use_embeddings=USE_EMBEDDINGS,
            character_name=character['name'],
            max_rephrase_attempts=MAX_REPHRASE_ATTEMPTS,
            min_improvement_threshold=MIN_RETRY_SCORE,
            verbose=verbose
        )
        
        if improved:
            if verbose:
                print(f"  [Two-Phase] Success: {result.keyword_score:.1f} → {new_result.keyword_score:.1f}")
            
            # Accept if good enough after rephrasing
            if new_result.keyword_score < MIN_RETRY_SCORE or not new_result.is_attracted:
                return rephrased, new_result, 1
            
            # Use rephrased as new baseline for potential full regeneration
            response = rephrased
            result = new_result
        else:
            if verbose:
                print(f"  [Two-Phase] No improvement, falling back to regeneration")
    
    # ========================================
    # FALLBACK: FULL REGENERATION
    # ========================================
    # Only reach here if two-phase didn't fully resolve the issue
    avoidance_prompt = ""
    attempts = [(response, result, 1)]  # Include initial/rephrased attempt
    
    for attempt in range(1, steering.config.max_regeneration_attempts):
        # Build avoidance prompt for retry
        avoidance_prompt = steering.get_avoidance_prompt(result)
        
        system_prompt, user_prompt = build_prompt(
            character, topic, context, topic_ctx, is_first_speaker, avoidance_prompt
        )
        
        response = call_llm(system_prompt, user_prompt)
        
        result = steering.detect(response, exempted_keywords=exempted, 
                                 intensity=intensity, use_embeddings=USE_EMBEDDINGS)
        
        attempts.append((response, result, attempt + 1))
        
        if verbose:
            status = "⚠️ ATTRACTOR MATCH" if result.is_attracted else "✓"
            print(f"  [Regen {attempt + 1}] {status} (score: {result.keyword_score:.1f})")
        
        # Accept if good enough
        if not result.is_attracted or result.keyword_score < MIN_RETRY_SCORE:
            return response, result, attempt + 1
    
    # All attempts exceeded threshold - pick the best one (lowest score)
    best = min(attempts, key=lambda x: x[1].keyword_score)
    best_response, best_result, best_attempt = best
    
    if verbose:
        if best_attempt != len(attempts):
            print(f"  [Selected attempt {best_attempt}] (score: {best_result.keyword_score:.1f})")
        print(f"  [Warning] Could not fully avoid attractors")
    
    return best_response, best_result, len(attempts)


# ============================================================================
# FORUM CLASS
# ============================================================================

class DebateForum:
    """Multi-character debate forum with attractor steering"""
    
    def __init__(self, steering: AttractorSteering):
        self.steering = steering
        self.history: List[Dict] = []
        self.topic_ctx: Optional[TopicContext] = None
        self.stats = Counter()
    
    def set_topic(self, topic: str):
        """Set new topic and analyze for exemptions using steering config"""
        self.topic_ctx = analyze_topic(topic, steering=self.steering)
        self.history = []
        print(f"\n{self.topic_ctx.summary()}")
    
    def get_context(self, max_messages: int = 6) -> str:
        """Get recent conversation context"""
        recent = self.history[-max_messages:]
        return "\n\n".join([f"[{msg['character']}]: {msg['message']}" for msg in recent])
    
    def respond(self, char_id: str, topic: str = None, is_first_speaker: bool = False) -> str:
        """Generate a response from a character"""
        
        if char_id not in CHARACTERS:
            return f"Unknown character: {char_id}"
        
        character = CHARACTERS[char_id]
        context = self.get_context()
        effective_topic = topic or (self.topic_ctx.topic if self.topic_ctx else "Continue the discussion")
        
        print(f"\n[{character['name']}] generating...")
        
        response, result, attempts = generate_with_steering(
            self.steering,
            char_id,
            effective_topic,
            context,
            self.topic_ctx,
            is_first_speaker
        )
        
        # Track stats
        for attractor in result.triggered_attractors:
            self.stats[attractor] += 1
        
        self.history.append({
            "character": character['name'],
            "message": response,
            "score": result.keyword_score,
            "attempts": attempts
        })
        
        return response
    
    def run_round(self, topic: str = None, char_order: List[str] = None):
        """Run a round with all characters"""
        
        if char_order is None:
            char_order = list(CHARACTERS.keys())
            random.shuffle(char_order)
        
        is_new_topic = topic is not None
        
        for i, char_id in enumerate(char_order):
            is_first = is_new_topic and (i == 0)
            
            if COMPARE_MODE:
                # Generate BOTH versions for comparison
                print(f"\n[{CHARACTERS[char_id]['name']}] generating comparison...")
                
                # Unfiltered version first
                print("  Generating UNFILTERED response...")
                unfiltered = generate_without_steering(
                    char_id, topic or self.topic_ctx.topic,
                    self.get_context(), self.topic_ctx, is_first
                )
                
                # Check what attractors it would have matched
                exempted = self.topic_ctx.exempted_keywords if self.topic_ctx else set()
                char_intensity = CHARACTERS[char_id].get('intensity', 0.5)
                unfiltered_result = self.steering.detect(
                    unfiltered, exempted_keywords=exempted, intensity=char_intensity
                )
                
                # Filtered version
                print("  Generating FILTERED response...")
                filtered, filtered_result, attempts = generate_with_steering(
                    self.steering, char_id, topic or self.topic_ctx.topic,
                    self.get_context(), self.topic_ctx, is_first, verbose=True
                )
                
                # Display comparison
                print(f"\n{'='*70}")
                print(f"[{CHARACTERS[char_id]['name']}] - COMPARISON")
                print(f"{'='*70}")
                
                print(f"\n{'─'*70}")
                print(f"UNFILTERED (score: {unfiltered_result.keyword_score:.1f})")
                print(f"{'─'*70}")
                print(unfiltered)
                if unfiltered_result.flagged_keywords:
                    print(f"\n  Flagged: {', '.join(unfiltered_result.flagged_keywords[:10])}")
                
                print(f"\n{'─'*70}")
                print(f"FILTERED (score: {filtered_result.keyword_score:.1f}, attempts: {attempts})")
                print(f"{'─'*70}")
                print(filtered)
                if filtered_result.flagged_keywords:
                    print(f"\n  Flagged: {', '.join(filtered_result.flagged_keywords[:10])}")
                
                # Add filtered version to history (for context in next round)
                self.history.append({
                    "character": CHARACTERS[char_id]['name'],
                    "message": filtered,
                    "score": filtered_result.keyword_score,
                    "attempts": attempts
                })
            else:
                # Normal mode - just filtered
                response = self.respond(char_id, topic, is_first_speaker=is_first)
                
                print(f"\n{'='*70}")
                print(f"[{CHARACTERS[char_id]['name']}]")
                print(f"{'='*70}")
                print(response)
    
    def show_stats(self):
        """Show session statistics"""
        print(f"\n{'='*70}")
        print("SESSION STATISTICS")
        print(f"{'='*70}")
        
        total = len(self.history)
        total_attempts = sum(msg.get('attempts', 1) for msg in self.history)
        
        print(f"Responses: {total}")
        print(f"Total attempts: {total_attempts}")
        print(f"Regeneration rate: {(total_attempts - total) / max(total, 1) * 100:.1f}%")
        
        if self.topic_ctx:
            print(f"\n{self.topic_ctx.summary()}")
        
        if self.stats:
            print(f"\nAttractors triggered (after steering):")
            for attractor, count in self.stats.most_common():
                print(f"  {attractor}: {count}")
    
    def save(self, filename: str = "debate_session.json"):
        """Save session to file"""
        with open(filename, 'w') as f:
            json.dump({
                "history": self.history,
                "stats": dict(self.stats),
                "topic": self.topic_ctx.topic if self.topic_ctx else None,
                "model": self.steering.config.model_name
            }, f, indent=2)
        print(f"Saved to {filename}")


# ============================================================================
# MAIN
# ============================================================================

def main():
    import sys
    global COMPARE_MODE, USE_DUAL_MODE, CONTROVERSIAL_WEIGHT
    
    # Parse arguments
    model_name = DEFAULT_MODEL_NAME
    config_dir = DEFAULT_CONFIG_DIR
    
    args = sys.argv[1:]
    i = 0
    while i < len(args):
        if args[i] == "--model" and i + 1 < len(args):
            model_name = args[i + 1]
            i += 2
        elif args[i] == "--config-dir" and i + 1 < len(args):
            config_dir = args[i + 1]
            i += 2
        elif args[i] == "--compare":
            COMPARE_MODE = True
            i += 1
        elif args[i] == "--dual":
            USE_DUAL_MODE = True
            i += 1
        elif args[i] == "--no-dual":
            USE_DUAL_MODE = False
            i += 1
        elif args[i] == "--controversial-weight" and i + 1 < len(args):
            try:
                CONTROVERSIAL_WEIGHT = float(args[i + 1])
            except ValueError:
                pass
            i += 2
        else:
            i += 1
    
    print("="*70)
    print("ATTRACTOR-AWARE DEBATE FORUM v4")
    print("="*70)
    print(f"\nBackend: {BACKEND}")
    print(f"Model config: {model_name}")
    if COMPARE_MODE:
        print(f"Mode: COMPARISON (showing filtered vs unfiltered)")
    
    # Load steering (try dual-mode first if enabled)
    steering = None
    if USE_DUAL_MODE:
        try:
            steering = load_dual_steering(model_name, config_dir, CONTROVERSIAL_WEIGHT)
            total_attractors = 0
            if steering.neutral_steering:
                total_attractors += len(steering.neutral_steering.config.attractors)
            if steering.controversial_steering:
                total_attractors += len(steering.controversial_steering.config.attractors)
            print(f"Dual-mode: {total_attractors} total attractors")
            print(f"Controversial weight: {CONTROVERSIAL_WEIGHT}x")
        except FileNotFoundError:
            print("Dual-mode not available, trying single-mode...")
            steering = None
    
    # Fallback to single-mode
    if steering is None:
        try:
            steering = load_steering(model_name, config_dir)
            print(f"Loaded {len(steering.config.attractors)} attractors (single-mode)")
        except FileNotFoundError as e:
            print(f"\nError: {e}")
            print("\nTo create a filter config, run the Lagrange Mapper pipeline:")
            print("  1. python Attractor_Pipeline_Runner.py")
            print("  2. Or run individual steps:")
            print("     python attractor_mapper.py")
            print("     python deep_analysis.py results.json")
            print("     python extract_filters.py results.json your-model --direct")
            return
    
    print(f"Keyword threshold: {steering.config.keyword_threshold}")
    print(f"Embedding threshold: {steering.config.embedding_threshold}")
    
    print(f"\nCharacters: {', '.join(CHARACTERS.keys())}")
    print("\nCommands:")
    print("  topic: <topic>     - Start new discussion")
    print("  round              - All characters respond")
    print("  respond <char>     - Specific character responds")
    print("  test <text>        - Test text for attractor matches")
    print("  stats              - Show statistics")
    print("  context            - Show current topic context")
    print("  save / quit")
    print("="*70)
    
    forum = DebateForum(steering)
    current_topic = None
    
    while True:
        try:
            cmd = input("\n> ").strip()
        except (EOFError, KeyboardInterrupt):
            break
        
        if not cmd:
            continue
        
        if cmd == "quit":
            break
        elif cmd == "save":
            forum.save()
        elif cmd == "stats":
            forum.show_stats()
        elif cmd == "context":
            if forum.topic_ctx:
                print(f"\n{forum.topic_ctx.summary()}")
            else:
                print("No topic set. Use 'topic: <topic>' first.")
        elif cmd.startswith("test "):
            text = cmd[5:]
            exempted = forum.topic_ctx.exempted_keywords if forum.topic_ctx else set()
            result = steering.detect(text, exempted_keywords=exempted, intensity=0.5)
            print(f"\n{result.summary()}")
        elif cmd.startswith("topic:"):
            current_topic = cmd[6:].strip()
            forum.set_topic(current_topic)
            print(f"\nStarting discussion: {current_topic}")
            forum.run_round(current_topic)
        elif cmd == "round":
            forum.run_round(current_topic)
        elif cmd.startswith("respond "):
            char_id = cmd[8:].strip()
            if char_id in CHARACTERS:
                response = forum.respond(char_id, current_topic)
                print(f"\n{'='*70}")
                print(f"[{CHARACTERS[char_id]['name']}]")
                print(f"{'='*70}")
                print(response)
            else:
                print(f"Unknown character. Available: {', '.join(CHARACTERS.keys())}")
        else:
            # Treat as human input
            forum.history.append({"character": "Human", "message": cmd})
            print("Added. Use 'round' or 'respond <char>' to continue.")


if __name__ == "__main__":
    main()
